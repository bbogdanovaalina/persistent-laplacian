{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbogdanovaalina/persistent-laplacian/blob/main/%D0%A1%D1%87%D0%B5%D1%82_%D0%BB%D0%B0%D0%BF%D0%BB%D0%B0%D1%81%D0%B8%D0%B0%D0%BD%D0%BE%D0%B2_%D0%B2%D1%82%D0%BE%D1%80%D0%BE%D0%B9_%D0%B2%D0%B0%D1%80%D0%B8%D0%B0%D0%BD%D1%82.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTpQgx8kJvFU",
        "outputId": "f83224fe-64d1-4b21-c592-267af422addd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dionysus\n",
            "  Downloading dionysus-2.0.8.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: dionysus\n",
            "  Building wheel for dionysus (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dionysus: filename=dionysus-2.0.8-cp37-cp37m-linux_x86_64.whl size=322709 sha256=449f34c245397dc0c0ef97109da3f89b8c73f5b62e3193979dc22d2888388dc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/bb/90/2e8a30f3af9a13951d8c76fa73689f6b8d87234c603bbd7003\n",
            "Successfully built dionysus\n",
            "Installing collected packages: dionysus\n",
            "Successfully installed dionysus-2.0.8\n"
          ]
        }
      ],
      "source": [
        "pip install dionysus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq-F0Wm5Q5-J",
        "outputId": "513cb0ab-8938-4e50-b06a-eb1a475fd965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gudhi\n",
            "  Downloading gudhi-3.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.3 MB 61.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from gudhi) (1.21.6)\n",
            "Installing collected packages: gudhi\n",
            "Successfully installed gudhi-3.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install gudhi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xnWy2JhJQ9wG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import dionysus as d\n",
        "from itertools import permutations\n",
        "from numpy import linalg\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import gudhi as gd\n",
        "from gudhi import SimplexTree\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC2PK83SnFZF"
      },
      "outputs": [],
      "source": [
        "points = np.loadtxt(names_con[2], delimiter = ',', skiprows = 1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "H3C5XNqQnR_s"
      },
      "outputs": [],
      "source": [
        "  # из набора points строим фильтрацию rips_list = список (вложенных комплекс, время рождения)\n",
        "\n",
        "\n",
        "def data1(file):\n",
        "\n",
        "    points = np.loadtxt(file, delimiter = ',', skiprows = 1)\n",
        "    corr_m = np.corrcoef(points, rowvar=False)\n",
        "    new_corr = 1 - abs(corr_m)\n",
        "    skeleton = gd.RipsComplex(new_corr)#, max_edge_length = 3) # тут максимальная длина ребра ОЧЕНЬ увеличивает время\n",
        "    Rips_simplex_tree_sample = skeleton.create_simplex_tree(max_dimension = 5)\n",
        "    #print(Rips_simplex_tree_sample.dimension(), ' - максимальная размерность симплексов')\n",
        "    #print(Rips_simplex_tree_sample.num_vertices(), ' - количество вершин')\n",
        "    #print(Rips_simplex_tree_sample.num_simplices(), ' - количество симплексов')\n",
        "    rips_generator = Rips_simplex_tree_sample.get_filtration()\n",
        "    rips_list = list(rips_generator)\n",
        "\n",
        "\n",
        "    def ind_of_compl(rips_list, dim=5, n=20):                                              \n",
        "        num_compl = 0\n",
        "        ans = 0\n",
        "        i = 0\n",
        "        while num_compl < n and i != len(rips_list):\n",
        "          if len(rips_list[i][0]) == dim + 1:\n",
        "            num_compl += 1\n",
        "            ans = i\n",
        "          i += 1\n",
        "        return ans\n",
        "\n",
        "    rips_list = rips_list[:ind_of_compl(rips_list, 5, 500) + 1]\n",
        "\n",
        "\n",
        "    number_of_simplicies = [len([i for i in rips_list if len(i[0])==1]),\n",
        "                                len([i for i in rips_list if len(i[0])==2]),\n",
        "                                    len([i for i in rips_list if len(i[0])==3]),\n",
        "                                        len([i for i in rips_list if len(i[0])==4]),\n",
        "                                            len([i for i in rips_list if len(i[0])==5]),\n",
        "                                                len([i for i in rips_list if len(i[0])==6])]\n",
        "    number_of_simplicies = np.array(number_of_simplicies)\n",
        "    number_of_vertices = number_of_simplicies[0]\n",
        "    for i in range(len(number_of_simplicies)):\n",
        "        print(number_of_simplicies[i], ' - количество комплексов размерности ', i)\n",
        "\n",
        "    # переделываем симплексы из SimplexTree в gudhi в SimplexTree из dionysus\n",
        "    d_rips_list = d.Filtration()\n",
        "    for vertices, time in rips_list:\n",
        "      d_rips_list.append(d.Simplex(vertices, time))\n",
        "    d_rips_list.sort()\n",
        "\n",
        "\n",
        "\n",
        "    # граничный оператор возвращает ориентацию грани i симплекса j\n",
        "    def boundary_sign(i, j):\n",
        "        for k in range(len(j) - 1):\n",
        "          if j[k] != i[k]:\n",
        "            if k % 2 == 0:\n",
        "              return 1\n",
        "            else:\n",
        "              return -1\n",
        "          if (len(j) - 1) % 2 == 0:\n",
        "            return 1\n",
        "          else:\n",
        "            return -1\n",
        "\n",
        "    # проверяет являются ли симплексы i и j (одинаковой размерности) смежными (то есть имеют общую грань на размерность меньше)\n",
        "    def adjacent(i, j):\n",
        "      face = set(i.boundary()).intersection(set(j.boundary()))\n",
        "      if len(face) > 0:\n",
        "          return True, list(face)[0] \n",
        "      else:\n",
        "        return False, []\n",
        "\n",
        "    # возвращает дополнение Шура к правой нижней матрице размера n_L - n_K в матрице M \n",
        "    def Schur_complement(M, n_K):  # M будет Delta^L_q,up , K - номер вложенного в L комплекса\n",
        "      n_L = len(M)\n",
        "      A = M[np.ix_(range(n_K), range(n_K))]\n",
        "      B = M[np.ix_(range(n_K), range(n_L - n_K, n_L))]\n",
        "      C = M[np.ix_(range(n_L - n_K, n_L), range(n_K))]\n",
        "      D = M[np.ix_(range(n_L - n_K, n_L), range(n_L - n_K, n_L))]\n",
        "      return A - np.dot(np.dot(B, linalg.pinv(D)), C)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def Fast_laplacian(K, L, q):\n",
        "      #Delta_q_K_down = D_down(K, q, d_rips_list, weights) - A_down(K, q, d_rips_list, weights)\n",
        "      #Delta_q_L_up = D_up(L, q, d_rips_list, weights) - A_up(L, q, d_rips_list, weights)\n",
        "      \n",
        "      d_rips_list_q_K = d.Filtration()\n",
        "      for i in range(K):\n",
        "        if d_rips_list[i].dimension() == q:\n",
        "          d_rips_list_q_K.append(d_rips_list[i])\n",
        "\n",
        "      d_rips_list_qm1_K = d.Filtration()\n",
        "      for i in range(K):\n",
        "        if d_rips_list[i].dimension() == q + 1:\n",
        "          d_rips_list_qm1_K.append(d_rips_list[i])\n",
        "\n",
        "      n_q_K = len(d_rips_list_q_K)\n",
        "\n",
        "      D_q_K_down = np.zeros(n_q_K)  \n",
        "      for i in range(n_q_K):\n",
        "        for sb in d_rips_list_q_K[i].boundary():\n",
        "          D_q_K_down[i] += 1 # тут вес(d_rips_list_q[i]) / вес(sb) вместо 1, если с весами\n",
        "\n",
        "      A_q_K_down = np.zeros((n_q_K, n_q_K))  \n",
        "      for i, j in permutations(d_rips_list_q_K, 2):\n",
        "        adj, l = adjacent(i, j)\n",
        "        if adj:\n",
        "          A_q_K_down[d_rips_list_q_K.index(i), d_rips_list_q_K.index(j)] += - boundary_sign(l, i) * boundary_sign(l, j) * 1# тут вес(i) / вес(l) вместо 1, если с весами\n",
        "    \n",
        "      Delta_q_K_down = np.diag(D_q_K_down) - A_q_K_down\n",
        "\n",
        "\n",
        "\n",
        "      d_rips_list_q_L = d.Filtration()\n",
        "      for i in range(L):\n",
        "        if d_rips_list[i].dimension() == q:\n",
        "          d_rips_list_q_L.append(d_rips_list[i])  \n",
        "\n",
        "      d_rips_list_qp1_L = d.Filtration()\n",
        "      for i in range(L):\n",
        "        if d_rips_list[i].dimension() == q + 1:\n",
        "          d_rips_list_qp1_L.append(d_rips_list[i])\n",
        "\n",
        "      n_q_L = len(d_rips_list_q_L)\n",
        "\n",
        "      A_q_L_up = np.zeros((n_q_L, (n_q_L)))  \n",
        "      for l in range(len(d_rips_list_qp1_L)):\n",
        "        for i, j in permutations(d_rips_list_qp1_L[l].boundary(), 2):\n",
        "          A_q_L_up[d_rips_list_q_L.index(i), d_rips_list_q_L.index(j)] += - boundary_sign(i, d_rips_list_qp1_L[l]) * boundary_sign(j, d_rips_list_qp1_L[l]) * 1# тут вес(d_rips_list_qp1[l]) / вес(j) вместо 1, если с весами\n",
        "\n",
        "      D_q_L_up = np.zeros(n_q_L)  \n",
        "      for s in d_rips_list_qp1_L:\n",
        "        for sb in s.boundary():\n",
        "          D_q_L_up[d_rips_list_q_L.index(sb)] += 1 # тут вес(s) / вес(sb) вместо 1, если с весами\n",
        "\n",
        "      Delta_q_L_up = np.diag(D_q_L_up) - A_q_L_up\n",
        "      \n",
        "      if n_q_L == n_q_K: \n",
        "        return Delta_q_K_down + Delta_q_L_up\n",
        "      else:\n",
        "        Delta_q_K_L_up = Schur_complement(Delta_q_L_up, n_q_K)\n",
        "      return Delta_q_K_down + Delta_q_K_L_up\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    res = [] # ответы\n",
        "\n",
        "    Q = 1\n",
        "    #p = 0.8\n",
        "    '''max_L = int(np.sum(number_of_simplicies[:3]) * p)\n",
        "    for L in (max_L // 2, max_L // 4 * 3, max_L):\n",
        "      for K in (L // 2, L // 4 * 3, L):'''\n",
        "\n",
        "    for L in (ind_of_compl(rips_list, Q, 300), ind_of_compl(rips_list, Q, 400), ind_of_compl(rips_list, Q, 500)):\n",
        "      for K in (L // 2, L):\n",
        "          res.append( sorted([i.real for i in np.linalg.eigvals(Fast_laplacian(K, L, Q))]) )\n",
        "            \n",
        "\n",
        "    Q = 2\n",
        "    #max_L = int(np.sum(number_of_simplicies[:4]) * p)\n",
        "    '''for L in (max_L // 2, max_L):\n",
        "      for K in (L // 2, L):'''\n",
        "    for L in (ind_of_compl(rips_list, Q, 300), ind_of_compl(rips_list, Q, 400), ind_of_compl(rips_list, Q, 500)):\n",
        "      for K in (L // 2, L):\n",
        "        res.append( sorted([i.real for i in np.linalg.eigvals(Fast_laplacian(K, L, Q))])  )\n",
        "       \n",
        "\n",
        "    Q = 3\n",
        "    #max_L = int(np.sum(number_of_simplicies[:5]) * p)\n",
        "    '''for L in (max_L // 2, max_L):\n",
        "      for K in (L // 2, L):'''\n",
        "    for L in (ind_of_compl(rips_list, Q, 300), ind_of_compl(rips_list, Q, 400), ind_of_compl(rips_list, Q, 500)):\n",
        "      for K in (L // 2, L):\n",
        "        res.append( sorted([i.real for i in np.linalg.eigvals(Fast_laplacian(K, L, Q))]) )\n",
        "        \n",
        "\n",
        "\n",
        "    Q = 4\n",
        "    #max_L = int(np.sum(number_of_simplicies) * p)\n",
        "    '''for L in (max_L // 2, max_L):\n",
        "      for K in (L // 2, L):'''\n",
        "    for L in (ind_of_compl(rips_list, Q, 450), ind_of_compl(rips_list, Q, 500)):\n",
        "      for K in (int(L * 0.6), int(L * 0.8), L):\n",
        "        res.append( sorted([i.real for i in np.linalg.eigvals(Fast_laplacian(K, L, Q))])  )\n",
        "       \n",
        "\n",
        "\n",
        "    Q = 5\n",
        "    '''for L in (max_L // 10 * 9, max_L):\n",
        "      for K in (L // 4 * 3, L):'''\n",
        "    for L in (ind_of_compl(rips_list, Q, 450), ind_of_compl(rips_list, Q, 500)):\n",
        "      for K in (int(L * 0.6), int(L * 0.8), L):\n",
        "        res.append( sorted([i.real for i in np.linalg.eigvals(Fast_laplacian(K, L, Q))])  )\n",
        "        \n",
        "\n",
        "    import csv\n",
        "\n",
        "    with open(file[:-4] + '_result.csv', \"w\", newline=\"\") as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerows(res)\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jlrXe5XjMiBO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dfba7a19-9032-42f0-bc11-9cef04cbd094"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"names_con = []\\nwith open('files_con_run_1.txt', 'r') as f:\\n    file = f.readlines()\\n    for line in file:\\n      if 'sub' in line:\\n        names_con.append(line[:-1])\\nf.close()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "names_pat = []\n",
        "with open('files_patients_MSDL_run_1.txt', 'r') as f:\n",
        "    file = f.readlines()\n",
        "    for line in file:\n",
        "      if 'sub' in line:\n",
        "        names_pat.append(line[:-1])\n",
        "f.close()\n",
        "\n",
        "'''names_con = []\n",
        "with open('files_con_run_1.txt', 'r') as f:\n",
        "    file = f.readlines()\n",
        "    for line in file:\n",
        "      if 'sub' in line:\n",
        "        names_con.append(line[:-1])\n",
        "f.close()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvrry3atMfe1"
      },
      "outputs": [],
      "source": [
        "num = 0\n",
        "n = 0\n",
        "for name in names_pat[num * 10: num * 10 + 10]:\n",
        "  data1(name)\n",
        "  print(n)\n",
        "  n += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ismOv-9d37B1"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PopEEEm3-yc"
      },
      "outputs": [],
      "source": [
        "for name in names_pat[num * 10: num * 10 + 10]:\n",
        "    files.download('/content/' + name[:-4] + '_result.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CON Финальная версия",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+uWtUE7WccJqQW4EBkwvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}